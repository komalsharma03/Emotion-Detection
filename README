## Emotion-Detection
Emotion Detection using Convolutional Neural Networks (CNNs).
This project aims to develop a comprehensive system that detects and classifies human emotions from uploaded images using Convolutional Neural Networks (CNNs). The application is built using Python and integrated into a user-friendly Streamlit interface. The project combines cutting-edge techniques from machine learning, computer vision, and user interface design to provide real-time emotion classification. The solution targets real-world applications in domains like healthcare, education, and customer service, where emotion recognition can offer valuable insights.
A deep learning-powered web application that detects human emotions from facial images using a Convolutional Neural Network (CNN), built with PyTorch and deployed via Streamlit.
📌 Table of Contents
Overview
Key Features
Tech Stack
System Architecture
Usage Guide
Model Details
Evaluation Metrics
Ethical Considerations
Project Report
🚀 Overview
This project demonstrates how deep learning and computer vision can be used to detect emotions in real-time from uploaded images. The application supports seven key emotions:
😃 Happy
😢 Sad
😠 Angry
😲 Surprised
😐 Neutral
🤢 Disgusted
😨 Fearful
The CNN model is trained using the FER-2013 dataset and deployed via Streamlit, allowing users to easily upload an image and instantly receive emotion predictions.
🌟 Key Features
Image Upload: Upload .jpg or .png images with clear human faces.
Real-time Emotion Detection: Fast inference with live feedback.
Model Confidence Score: Displays prediction confidence.
Evaluation Metrics: Reports precision, recall, accuracy, and F1-score.
Clean UI: User-friendly interface powered by Streamlit.
🛠️ Tech Stack
Python 3.x
PyTorch – Model training and inference
Torchvision – Data preprocessing and transformation
Streamlit – Web interface for image upload and result display
PIL (Pillow) – Image handling
FER-2013 Dataset – Facial expression recognition dataset from Kaggle
🧩 System Architecture
Frontend:Streamlit-based interface for uploading images and displaying results.
Backend:Image preprocessing
Emotion prediction using a trained CNN
Result rendering with confidence level
Model Pipeline:Face detection → Preprocessing → Model Inference → Result Output
📸 Usage Guide
Steps to Run the App:
1 Clone the repository:
2 Install dependencies:
3 Launch the Streamlit app: streamlit run emotion.py
Upload an image with a visible face.
View the predicted emotion and confidence score instantly.
🧠 Model Details
The CNN model consists of:
Multiple Convolutional Layers for feature extraction
ReLU Activation and MaxPooling
Fully Connected Layers for classification
Softmax Output Layer for multi-class prediction
The model was trained using:
Optimizer: Adam
Loss Function: CrossEntropyLoss
Dataset: FER-2013
Classes: 7 Emotions
📊 Evaluation Metrics
The model was evaluated using:
Accuracy – Overall correctness of predictions
Precision – How many predicted positives were correct
Recall – How many actual positives were identified
F1 Score – Balance between precision and recall
🧭 Ethical Considerations
User Privacy: No images are stored or shared; all processing is done locally and temporarily.
Bias Awareness: The FER-2013 dataset may not represent all ethnicities or age groups equally. Future versions aim to use more diverse datasets.
Responsible Use: Avoid using emotion detection for surveillance or emotional manipulation. Always use with transparency and user consent.




