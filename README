## Emotion-Detection
Emotion Detection using Convolutional Neural Networks (CNNs).
This project aims to develop a comprehensive system that detects and classifies human emotions from uploaded images using Convolutional Neural Networks (CNNs). The application is built using Python and integrated into a user-friendly Streamlit interface. The project combines cutting-edge techniques from machine learning, computer vision, and user interface design to provide real-time emotion classification. The solution targets real-world applications in domains like healthcare, education, and customer service, where emotion recognition can offer valuable insights.
A deep learning-powered web application that detects human emotions from facial images using a Convolutional Neural Network (CNN), built with PyTorch and deployed via Streamlit.
ğŸ“Œ Table of Contents
Overview
Key Features
Tech Stack
System Architecture
Usage Guide
Model Details
Evaluation Metrics
Ethical Considerations
Project Report
ğŸš€ Overview
This project demonstrates how deep learning and computer vision can be used to detect emotions in real-time from uploaded images. The application supports seven key emotions:
ğŸ˜ƒ Happy
ğŸ˜¢ Sad
ğŸ˜  Angry
ğŸ˜² Surprised
ğŸ˜ Neutral
ğŸ¤¢ Disgusted
ğŸ˜¨ Fearful
The CNN model is trained using the FER-2013 dataset and deployed via Streamlit, allowing users to easily upload an image and instantly receive emotion predictions.
ğŸŒŸ Key Features
Image Upload: Upload .jpg or .png images with clear human faces.
Real-time Emotion Detection: Fast inference with live feedback.
Model Confidence Score: Displays prediction confidence.
Evaluation Metrics: Reports precision, recall, accuracy, and F1-score.
Clean UI: User-friendly interface powered by Streamlit.
ğŸ› ï¸ Tech Stack
Python 3.x
PyTorch â€“ Model training and inference
Torchvision â€“ Data preprocessing and transformation
Streamlit â€“ Web interface for image upload and result display
PIL (Pillow) â€“ Image handling
FER-2013 Dataset â€“ Facial expression recognition dataset from Kaggle
ğŸ§© System Architecture
Frontend:Streamlit-based interface for uploading images and displaying results.
Backend:Image preprocessing
Emotion prediction using a trained CNN
Result rendering with confidence level
Model Pipeline:Face detection â†’ Preprocessing â†’ Model Inference â†’ Result Output
ğŸ“¸ Usage Guide
Steps to Run the App:
1 Clone the repository:
2 Install dependencies:
3 Launch the Streamlit app: streamlit run emotion.py
Upload an image with a visible face.
View the predicted emotion and confidence score instantly.
ğŸ§  Model Details
The CNN model consists of:
Multiple Convolutional Layers for feature extraction
ReLU Activation and MaxPooling
Fully Connected Layers for classification
Softmax Output Layer for multi-class prediction
The model was trained using:
Optimizer: Adam
Loss Function: CrossEntropyLoss
Dataset: FER-2013
Classes: 7 Emotions
ğŸ“Š Evaluation Metrics
The model was evaluated using:
Accuracy â€“ Overall correctness of predictions
Precision â€“ How many predicted positives were correct
Recall â€“ How many actual positives were identified
F1 Score â€“ Balance between precision and recall
ğŸ§­ Ethical Considerations
User Privacy: No images are stored or shared; all processing is done locally and temporarily.
Bias Awareness: The FER-2013 dataset may not represent all ethnicities or age groups equally. Future versions aim to use more diverse datasets.
Responsible Use: Avoid using emotion detection for surveillance or emotional manipulation. Always use with transparency and user consent.




